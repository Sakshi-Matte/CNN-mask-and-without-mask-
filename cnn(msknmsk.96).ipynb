{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1f96c11-3821-4eb2-9f3f-a294c9746071",
   "metadata": {},
   "outputs": [],
   "source": [
    "path1= r\"D:\\masknomask\"\n",
    "cate=['with_mask','without_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06dbe80c-fbc4-4b66-90bc-9a933287f7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPool2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c276a02d-48a2-4896-845b-5af9a07bff3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size=200\n",
    "\n",
    "path1= r\"D:\\masknomask\"\n",
    "cate=['with_mask','without_mask']\n",
    "\n",
    "input_image=[]  #empty list\n",
    "for i in cate:\n",
    "    folders=os.path.join(path1,i)\n",
    "    label=cate.index(i)\n",
    "  #  j=0               debugging used when resize error occurs\n",
    "    for image in os.listdir(folders):\n",
    "        image_path=os.path.join(folders,image)\n",
    "        image_array=cv2.imread(image_path)\n",
    "       # print(j)\n",
    "       # j=j+1\n",
    "        image_array=cv2.resize(image_array,(image_size , image_size))\n",
    "        input_image.append([image_array,label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f6349bd-6463-44ae-9978-0f168513c194",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bcdf4b5-a3da-4b1f-9d58-c0f9ad2a3726",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "Y=[]\n",
    "for X_values, labels in input_image:\n",
    "    X.append(X_values)\n",
    "    Y.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7203e6f7-5146-40de-ab20-3cb9ff92728a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X[0:3066]\n",
    "X_test=X[3066:3833]\n",
    "Y_train=Y[0:3066]\n",
    "Y_test=Y[3066:3833]\n",
    "\n",
    "X_train=np.array(X_train)\n",
    "Y_train=np.array(Y_train)\n",
    "X_test=np.array(X_test)\n",
    "Y_test=np.array(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "665e9e78-6d68-4284-b5c7-75852cf3a75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train/225\n",
    "X_test=X_test/225"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8dc6321a-dd2e-4165-a986-f974fbbc54db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense,Dropout\n",
    "\n",
    "input_shape = (200, 200, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu',input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu')) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))  # Removed `input_image` argument\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf9f638d-81c9-4984-aa6c-9a197507a58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f28f21d0-487c-4e2b-ae3e-6c544bddb010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 4s/step - accuracy: 0.6042 - loss: 0.6795 - val_accuracy: 0.8225 - val_loss: 0.4190\n",
      "Epoch 2/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 3s/step - accuracy: 0.8978 - loss: 0.2865 - val_accuracy: 0.9121 - val_loss: 0.2206\n",
      "Epoch 3/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3s/step - accuracy: 0.9374 - loss: 0.1883 - val_accuracy: 0.9267 - val_loss: 0.1907\n",
      "Epoch 4/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 3s/step - accuracy: 0.9320 - loss: 0.1759 - val_accuracy: 0.9446 - val_loss: 0.1553\n",
      "Epoch 5/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 3s/step - accuracy: 0.9519 - loss: 0.1383 - val_accuracy: 0.9414 - val_loss: 0.1755\n",
      "Epoch 6/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3s/step - accuracy: 0.9392 - loss: 0.1650 - val_accuracy: 0.9446 - val_loss: 0.1440\n",
      "Epoch 7/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 3s/step - accuracy: 0.9624 - loss: 0.1181 - val_accuracy: 0.9365 - val_loss: 0.1630\n",
      "Epoch 8/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 3s/step - accuracy: 0.9591 - loss: 0.1228 - val_accuracy: 0.9495 - val_loss: 0.1387\n",
      "Epoch 9/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 4s/step - accuracy: 0.9571 - loss: 0.1106 - val_accuracy: 0.9544 - val_loss: 0.1311\n",
      "Epoch 10/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 4s/step - accuracy: 0.9720 - loss: 0.0749 - val_accuracy: 0.9544 - val_loss: 0.1090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x195448ff320>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train,validation_split=0.2, epochs=10,batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93626154-6255-4ee6-9177-b5ffd0415978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 439ms/step\n",
      "Confusion Matrix:\n",
      "[[386  11]\n",
      " [ 20 350]]\n",
      "------------------------------------------------------\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       397\n",
      "           1       0.97      0.95      0.96       370\n",
      "\n",
      "    accuracy                           0.96       767\n",
      "   macro avg       0.96      0.96      0.96       767\n",
      "weighted avg       0.96      0.96      0.96       767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "pred_classes = pred.argmax(axis=1)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "tab = confusion_matrix(Y_test, pred_classes)\n",
    "print('Confusion Matrix:')\n",
    "print(tab)\n",
    "print('------------------------------------------------------')\n",
    "print('Classification Report:')\n",
    "print(classification_report(Y_test, pred_classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
